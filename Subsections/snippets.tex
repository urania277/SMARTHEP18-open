

%%%REPETITION ALARM
The success of \acronym  will provide Europe with a new generation of scientists with 
expertise in both HEP and DS with a focus on RTA, and experience in the commercial sector. 
The project will increase the portability of HEP techniques to 
other fields, and deliver novel commercial solutions for the real-time processing of big data.
%%%END REPETITION ALARM


%%%REPETITION ALARM
\acronym addresses the challenges raised by the abundance of data 
and the necessity for fast and efficient selection towards further analysis in
both HEP and commercial applications by moving towards RTA techniques.
These are enabled by advanced data analysis and Machine Learning (ML) algorithms 
deployed on a variety of platforms, from software in ordinary computers (CPUs) 
to hybrid hardware/software solutions (Graphical Processing Units) to hardware architectures
such as Field Programmable Gate Arrays and mobile phone chips. %CD: not sure this division works
%%Each of the four research WPs concerns itself with a specific RO of \acronym.
Through secondments and PhD program, 
each ESR is involved in multiple WPs that focus on concrete HEP and commercial problems,
within an interconnected and interdisciplinary research program. 
%%%END REPETITION ALARM

%%%REPETITION ALARM
\acronym will train 15 ESRs to solve a set of research problems involving 
taking decisions fast and efficiently. Throughout their training and beyond, 
the ESRs will be able to optimally apply RTA techniques 
to existing HEP experiments, their upgrades, future proposed experiments
and commercial data analysis. 
%%%REPETITION ALARM

All \acronym participants face challenges that require making decisions fast and efficiently, 
and solve it through training and research on RTA, in order to advance HEP and society. 


The specific examples considered in \acronym 
span a range of applications in the two key topics, and are well linked to each of the ESR's thesis topics to ensure
that the complementarity between HEP and industry challenges is fully exploited. 

MOVE THIS STUFF TO A TWO-TOPIC BULLET LIST IN DESCRIPTION OF RESEARCH

CARS

The prediction of automotive traffic in mobile apps in \ximantisentity needs to happen on the order of seconds
after the driver has communicated its position to the app, so that the driver can decide how
to reroute their vehicle. This is the same issue that a ML application will solve etc etc. 

Modern mobile platforms are one of the key interest of \fleetmaticsentity and
offer a number of pattern recognition features used in association with built-in cameras, 
allowing users to identify objects, faces or context in the timescales of fractions of seconds before the picture is taken
and decide what to focus on. REWRITE TO CARS




SENSORS AND IOT - mention CERN's Internet Of Things thing
 
The expertise and needs of \ibmentity concerning automatic anomaly detection is essential to 
distinguish rare processes in HEP and efficiently monitor and flag a variety of industrial and financial processes. 

The concrete problem offered by \lightboxentity is the 
acquisition of a wide variety of sensor data during industrial production
processes and its analysis in the timescale of seconds, in order to decide when machinery
in industrial processes is going to need maintenance of replacement without 
disrupting the production chain. 

\wildtreeentity plans to design a smart monitoring system 
that decides when to temporarily deactivate and reactivate fractions of groups of 
computers to save resources and allow a rapid substitution of failed components. CHECK THIS


The simulation of medical surgery designed by \cathientity
gathers input from many simulated sensors implemented in hardware, and needs to produce
a realistic response on the timescale below the second, in order to provide a viable training
ground for medical students and doctors. 

Finally, \heidelberginstrumentsentity aims to
transfer the experience gathered from the FPGAs in the ATLAS trigger system to process a correction to a laser system with
an input rate of 300000 events per second. 



%\acronym targets a coherent set of problems involving taking decisions fast and efficiently. 


%These Real-Time Analysis techniques (RTA) are enabled by advanced data analysis and Machine Learning (ML) algorithms 
%deployed on a variety of platforms, from software in ordinary computers (CPUs) 
%to hybrid hardware/software solutions (Graphical Processing Units) to pure hardware architectures
%such as Field Programmable Gate Arrays and mobile phone chips. %CD: not sure this division works

Data collection and data analysis are 
a key part of the experimental process, as the model properties can only be inferred
from the observation of the outcome of a large number of particle collisions, 
also called \textit{events}
%\footnote{Tab.~\ref{tab:notation} defines some key terminology which will be
%used throughout this document.}.
The large number of collisions create huge amount of data, which needs
to be processed and analysed to extract interesting information. 


%%1. training

HEP experiments are by their very nature built around \textbf{training}, 
as around a third of all LHC collaborations consist of PhD students.
%and over half are either students or early-career (non-tenured) researchers.
This combination of a collaborative, training-based research culture, and a focus on the largest datasets
produced in the world using beyond state-of-the-art technology
leads to the proposal of \acronym as a training-centered research programme in the HEP and DS disciplines.


%{\color{blue}{\acronym enables real-time data analysis through machine learning and hybrid architectures.}}
%{\color{blue}{\acronym has an intersector, interdisciplinary structure to achieve its goals}.}

%%%Physics

%Add citations? ~\cite{Bertone:2004pz},

This is the first step towards a systematic real-time calibration and alignment of the whole detector,
which is paradigm-shifting for HEP as a whole. 
Related techniques are also necessary to probe new physics models that otherwise would be 
inaccessible due to the sheer amount of data produced by the LHC: the proponents of \acronym within the ATLAS experiment
are in the process of performing the first trigger-level new physics search for the experiment~\footnote{See \href{https://cds.cern.ch/record/2063491}{https://cds.cern.ch/record/2063491} 
for the CMS experiment and ERC grant agreement No. 679305}.
The extension of this analysis using multivariate
algorithms as mentioned in this project would be a novel development.  
In addition, laying the foundations for such
a calibration technique over the ten or twenty year lifespans of the LHC experiments and prototypes 
of experiments at future colliders will necessarily lead
to crucial knowledge transfer back into industrial applications.

%Most prominent explanations of the measured anomaly in LFU involve new
%scalar or vector particles, specifically
%leptoquarks~\cite{rk_lepto1,rk_lepto2,lepto3} or new $Z'^{0}$ gauge 
%bosons~\cite{rk_zprime1,rk_zprime2,rk_zprime3}.
%If any of these models would be confirmed, it would be a revolutionary
%discovery for the field of particle physics and would constitute the
%discovery of a new fundamental force. 


%\begin{itemize}
%	\item The associated production of a Higgs boson with a pair of top quarks, and its decay mode $H\to\tau\tau$ 
%	provide crucial measurements of the Higgs boson properties~\footnote{See for example
%	\\ \href{http://atlas.ch/physics-briefs/precise-measurement-of-the-higgs-boson-mass-by-the-ATLAS-experiment.html}{http://atlas.ch/physics-briefs/precise-measurement-of-the-higgs-boson-mass-by-the-ATLAS-experiment.html}} and will be studied in ESR1 and ESR12.
%	\item The analyses studied in ESR4 and ESR13 are among the most promising signatures of physics beyond the SM\footnote{See for example arXiv papers \href{http://arxiv.org/abs/1402.5939}{1402.5939}, \href{http://arxiv.org/abs/1305.3818}{1305.3818} and \href{http://arxiv.org/abs/1102.0302}{1102.0302}.}.
%    \item Searches for lepton flavour violation are also important New
%      Physics benchmarks\footnote{See for example arxiv
%        \href{http://arxiv.org/abs/1511.08880}{1511.08880} or
%        \href{http://arxiv.org/abs/1511.06024v2}{1511.06024v2}.}, and
%      RTA will significantly enhance LHCb's reach by
%      enabling to trigger modes like $\tau\to\mu\gamma$, which will be analyzed by ESR8.
%\end{itemize}
%
%{\color{blue}{\acronym uses beyond-state-of-the-art technologies}}

%Write a sentence about FTK, gFEX, TPC. Text from LPNHE ESR: 
% 
%The ATLAS trigger infrastructure has an unique hardware processor to reconstruct the trajectory (tracking) 
%of the charged particles that cross the silicon inner tracker of the experiment. The tracking information 
%is essential for effective real-time event selection and has a central role in the whole 
%ATLAS physics program especially in the HL-LHC phase. The current hardware processor, FTK, is a
%complex system made by several custom electronics  boards based on FPGAs and Associative Memory chips.
%The latter are unique computing devices developed for the FTK algorithm. The hardware tracking will be also
%a central part of the Phase-II Upgrade of ATLAS, with upgraded version of FTK called FTK++.



%Write more here: what can we not do without FTK, why track triggers are important

%Text on self-calibration for LHCb, removed since there's not much about it in ESRs.
%Automatically calibrating detectors in real-time has never been implemented
%before on anything near this scale. During the first LHC run, the LHC detectors were calibrated offline, and
%these calibrations were propagated to the trigger systems only when major changes were detected, typically
%a few times per year.  Since then, \acronym proponents have been the driving force for the 
%LHCb experiment to calibrate certain parts of the detector\footnote{Notably the
%gaseous Ring-Imagining Cherenkov Detectors which allow LHCb to distinguish different kinds of charged hadrons, and
%whose performance is highly sensitive to small variations in the temperature and pressure of the gas.}
%in real-time during 2015.%~\footnote{See \href{http://lhcb-doc.web.cern.ch/lhcb-doc/presentations/Seminars/Storaci_LHCb_runII.pdf}{http://lhcb-doc.web.cern.ch/lhcb-doc/presentations/Seminars/Storaci_LHCb_runII.pdf}}. 


LHCb has played a pioneering role in multivariate triggering~\footnote{See \href{https://inspirehep.net/record/1193348?ln=en}{https://inspirehep.net/record/1193348?ln=en} and
\href{https://inspirehep.net/record/1202496?ln=en}{https://inspirehep.net/record/1202496?ln=en}.}.
However, even in this very successful implementation, the reconstruction cost was 
optimized by hand and the reconstruction simply provided objects for the separately
optimized multivariate classification. 
The systematic use of multivariate triggers, deep learning calorimeter and jet 
reconstruction techniques at once would be novel to the ATLAS experiment.
Finally, the proposed research into new figures of merit for multivariate classifiers is both original
and necessary. While controlling systematics is key to enabling permille precision measurements
at the LHC, whether in the study of hadrons containing bottom quarks or Higgs decays, we 
know of no multivariate HEP analysis whose classifier was optimized for the smallest
systematic uncertainty.


