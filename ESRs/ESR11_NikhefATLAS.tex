%\begin{table}[h]

%\begin{table}[h]
\begin{center}\small
\resizebox {\textwidth }{!}{%
\begin{tabular}{|p{21mm}|p{19mm}|p{15mm}|p{8mm}p{12mm}|p{19mm}|p{39mm}|p{38mm}|}
\hline
\textbf{\Tstrut Fellow} \,\,ESR11&
\textbf{Host} \,\,\nikhef&
\textbf{\phd} \,\,Yes&
\textbf{Start} & Month 8&
\textbf{Duration} \,\,36&
\textbf{Deliverables} \deliverableWhitepaperStateOfTheArtWPThree,\deliverableWhitepaperDevelopmentWPThree,\deliverableTriggerExperimentalSoftwareWPThree,\deliverableWhitepaperDevelopmentWPFour,\deliverableWhitepaperStateOfTheArtWPFive,\deliverableWhitepaperCollectionPapersWPFive, \deliverableUltrasoundSimulation &
\textbf{Work Package:} WP3,4,5,6\tabularnewline 
%ESR11 &  \nikhef & Yes & Month 6& 36 & \deliverableTechPubMLForOptimisation \deliverableTriggerOptToolkit \deliverableUltrasoundSimulation \deliverableHEPPubLFVATLAS \tabularnewline
\hline
%\multicolumn{2}{|l|}{\textbf{\Tstrut Work Package:}
%WP3,4,5,6,7} &
\multicolumn{4}{|l|}{\textbf{Doctoral programme:} \radboudlong }& %\tabularnewline\hline
\multicolumn{4}{l|}{\textbf{\Tstrut Title: Optimization of RTA resources and LFV search with ATLAS}
}\tabularnewline\hline
\multicolumn{8}{|p{20.2cm}|}{\textbf{\Tstrut Objectives:}
ESR11 will study and be trained in advanced ML methods for RTA in both HEP and industry, and apply these methods to the optimization of resources for RTA, searches for LFV, and the optimization of ultrasound image simulation.
%This project aims to bring advanced machine learning tools into trigger and analysis. 
Instead of focusing on specific physics processes and separation of signal 
versus background based on their characteristics, ESR11 investigate a more generic approach - 
what are the bottlenecks in our trigger algorithms, what prevents us to record events we want and how to do more exciting physics with the same or even less resources we have. 
%This generic approach allows the project to be conducted in particular synergy with ESR12, also at \nikhefentity, and ESR10 (\sorbonneentity) 
%For main text
%The typical bottlenecks for real-time data processing are : available CPU, available memory and available disk space. 
%The main limitations come from necessity to accomplish the work in very specific and short t ime as well as
%necessity to reduce the incoming data by factor within few milliseconds.
%ATLAS covers a huge variety of interesting physics processes, 
%with a scientific output of a few hundred peer reviewed papers per year. 
%The data selection and data analysis system that makes this rich physics program possible 
%consists of a few thousands lines of code called "trigger lines", 
%developed by a hundred of physicists with different programming skills. 
%Even though a highly trained and experienced team of physicists writes and optimizes this software,
%it still requires many tests as some parts of it are still manually edited and therefore error prone. 
%Further, the constant improvement on the LHC performance (high luminosity of events, higher density of
%interactions, higher volume of data) 
%makes 
%The optimization of trigger software and hardware is an ongoing, ever-evolving challenge that follows constant improvement of the LHC accelerator performance. 
ESR11's first objective will be to simplify, streamline and optimize the process of testing and benchmarking ATLAS triggers, 
by creating software tools that will analyze the performance of each trigger line, 
the resources used by each line, and their commonalities. ESR11 will also study how to reduce the consumption of resources by trigger lines using ML algorithms. A secondment at CERN under the supervision of 
physicists from the \oregonentity will prove that these tools are useful within
the ATLAS trigger, testing the performance of the algorithms developed by ESR15 on real data.
As the tools developed by ESR11 will not use any physics characteristics 
%(except for "physics independent approach", when such characteristics are used to group 
%triggers together or to select the most optimal step without loose of physics performance), 
they will be portable and useful for applications independently of the experiment. 
Specifically, we will design the tools together with LHCb trigger colleagues (ESR12), and for different computing architectures (ESR10).
%as the LHCb experiment has a similarly complex trigger system and a similarly
%complex set of limitations/bottlenecks, where such tools could be applied.
ESR11's second objective will be to search for LFV in the $\tau\to 3\mu$ process 
with ATLAS data, where the optimization of the analysis chain resource consumption
%(with less focus on resources and more focus on characteristics of background processes) 
is critical and will use the tools developed by ESR11.% and needs to be specified. 
%At this point is not clear how to preserve this very 
%challenging physics process at the ATLAS trigger system. 
%The application of the tools that ESR11 will design in this project is a critical ingredient
%for a discovery of this process.
%Such benchmarking and optimisation tools are software independent and are useful outside the 
%HEP environment, for example in industrial groups managing large software projects. 
To make these tools fully environment independent, ESR11 will collaborate with the industrial partner
\cathientity to test these tools in their environment, in particular
%The practical use case to be tested within the secondment with \cathi
the integration of real-time medical ultrasound simulation within the \cathiSimulator. 
%Ultrasound simulation requires simulating ultrasound wave interactions with the 3D representation of organs 
%using highly parallel computing, providing a 2D image similar to real medical ultrasound image as output. 
%It is important that the radiated wave propagation and the image reconstruction are
%performed in real-time for the \cathiSimulator to be effective in training medical 
%students and specialists as they were working on real patients, and as such this process needs to be optimised. 
The student will refactor the existing ultrasound simulation code and optimise its performance using 
the benchmarking tools developed within the first part of the project, and 
implement the simulation algorithms on a GPU for maximal parallelization. 
During this secondment ESR11 will be trained in C++ and parallel programming, programming for GPU (Nvidia CUDA) and acquire
a basic understanding of physical principles of medical ultrasound imaging and image processing. 
%Original text
%Medical Ultrasound is one of the most important techniques used in modern medical imaging. 
%In order to provide a possibility for medical students and specialists to train and improve their skills in this technique, we are integrating real-time medical ultrasound simulation into CATHISÂ® Simulator.
%The project operates with such concepts as a 3D scene, an ultrasound transducer and a 2D ultrasound image. 
%The 3D scene consists of several objects located in 3D space and represented as mesh models (sets of polygons). 
%The ultrasound transducer is basically a source of ultrasound waves radiated from a given position into a predefined
%direction within the scene. So, the transducer can be considered as a pair (position, direction) and a set of parameters (constants)
%that define some physical properties of the radiated ultrasound waves. The waves interact with the objects within the 3D scene 
%(reflection, refraction) and return to the transducer with different delays and energies, forming ?a scan? of the scene.
%This scan is called a 2D ultrasound image. Formally, the basic idea of the simulation module consists in real-time mapping of
%the transducer object within the 3D scene into the corresponding 2D ultrasound image. This can be described using the following simplified scheme:
%? Input: a) 3D scene representing a set of 3D-mesh organs with some predefined tissue properties, b) ultrasound transducer (source and detector of ultrasound waves) in 3D defined by (position, direction);
%? Processing: simulation of ultrasound waves interaction with the objects using highly parallel
%computing;
%? Output: 2D image similar to real medical ultrasound images;
%The implementation of the module includes such real-time tasks as radiated wave propagation and image reconstruction. 
%The wave propagation process is simulated using an approximation model. It is important that the above tasks are solved in real-time as the developed ultrasound module is considered to be a part of CATHIS simulator. Therefore, the main objectives of the project are:
%? Refactoring of the programming code and performance optimization of the ultrasound simulation module (C++);
%? Implementation of the most important algorithms on a GPU for maximal parallelization;
%During this project a student will improve his/her skills in parallel programming (C++ and Nvidia CUDA), code optimization and real-time image processing.
%within the Ultrasound project we have only two principal limitations: 1) the final ultrasound image must be quite realistic 2) the image must be generated in real-time. The first means that we have to find a simulation method that produces appropriate quality. In the beginning it could be done using a programming environment that is suitable for modelling and experimenting (e.g. C++ on a single CPU or MATLAB). The second means that we will need to accelerate the algorithm, and here a GPU is probably the only possibility, with all that it entails (limited GPU memory, quite low-level programming style with specific code-design etc.). The speed must be at least several images per second, so if the final accelerated algorithm is slower than this, we will need to find a trade-off between the quality and the speed. Possibly a good idea is to use Nvidia OptiX framework, we already have some prototypes working on it (not in a very optimal way, as OptiX is designed for ray tracing and not for wave propagation). In this case a lot of pure GPU programming will be reduced to utilization of this framework (never the less this also requires programming in CUDA) and optimization of the algorithm speed/quality.
}\tabularnewline\hline
\multicolumn{8}{|p{20.2cm}|}{\textbf{\Tstrut Expected Results:}
Inter-experiment toolkit for trigger benchmarking and optimization (with ESR12), 
a related peer-reviewed publication, a technical publication on used ML methods. The toolkit will be released for use in industry, and contribute
to an optimized module for the \cathiSimulator ultrasound simulation. 
%ML methods used in the toolkit will be documented separately in a technical publication.
The physics research will lead to a peer-reviewed publication on LFV.
% - Improved ATLAS trigger performance, allowing more physics channels and therefore more scientific output
% - industry  quality tool to speed up software and limit its CPU and memory consumption .
% - Preservation of lepton flavor analysis tau to 3 muons at high luminosity LHC
% - development of SMART tools to improve physics performance by optimizing resources and reusing common parts
% - application of SMART tools to an alternative software project such as LHCb experiment and CATHY firm software
% - paper on machine learning optimization based on resources and not on output parameters
% - paper on trigger for Lepton Flavor Violation of tau to 3 muons with ATLAS
ESR11 will receive a PhD in experimental HEP at \radboudentity.
}\tabularnewline\hline

%\multicolumn{6}{|p{20.2cm}|}{\textbf{Doctoral program:} Cambridge}\tabularnewline\hline
\multicolumn{8}{|p{20.2cm}|}{\textbf{\Tstrut Secondments:}
\cathientity, 4 months, Hlindzich. Optimization and parallelization of the ultrasound simulation code within \cathiSimulator. 
\oregonentity (at CERN), 5 months, Strom. Benchmarking of algorithms for energy clustering in the ATLAS trigger. 
}\tabularnewline
\hline
\end{tabular}
}%
\end{center}
%\end{table}
%
