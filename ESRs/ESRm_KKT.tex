%\begin{table}[h]
\begin{center}\small
\resizebox {\textwidth }{!}{%
\begin{tabular}{|p{25mm}|p{23mm}|p{18mm}|p{28mm}|p{34mm}|p{60mm}|}
\hline
\textbf{\Tstrut Fellow} \,\,\ESRm&
\textbf{Host} \,\,\fleetmaticsentity&
\textbf{\phd} \,\,Yes&
\textbf{Start (mo.)} \,\,8&
\textbf{Duration (mo.)} \,\,36&
\textbf{Deliverables}\,\,\deliverableWhitepaperStateOfTheArtWPThree,\deliverableWhitepaperDevelopmentWPThree, \deliverableDashboardCam \tabularnewline 
\hline
\multicolumn{2}{|l|}{\textbf{\Tstrut Work Package:}
\WPESRa} &
\multicolumn{2}{l|}{\textbf{Doctoral programme:} \uniboentity }&%\tabularnewline\hline
\multicolumn{2}{l|}{\textbf{\Tstrut Title: RTA through computer vision on dashcams}
}\tabularnewline\hline
\multicolumn{6}{|p{21.2cm}|}{\textbf{\Tstrut Objectives:}
\ESRm will be trained in state-of-the-art computer vision algorithms based on deep learning and will study how to adapt and specialize them for RTA of videos collected by dashcams (camera on vehicle) installed on \fleetmatics customers.
In particular, two classical problems in modern computer vision are depth from monocular images and semantic segmentation. 
Depth from monocular images is concerned with creating algorithms that can estimate the metric distance of objects from the camera using only one image, a problem traditionally solved with two cameras (stereo setup). Semantic segmentation algorithms assign a label among a predefined set of classes to every pixel of an input image (e.g. road, grass, pavement, pedestrian, etc...). 
The state-of-the-art approaches in both problems are nowadays based on highly-specialized deep learning pipelines, which require powerful GPUs to achieve real-time performance. 
Therefore, they are not suitable for deployment in smart dashcams to analyze video streams according to an edge-computing paradigm. 
The first objective of \ESRm will be the development and field testing of algorithms to compute depth from monocular images and semantic segmentation suitable for resource-constrained platforms, like the nVidia Jetson TX2, Ambarella CV2AQ, or Raspberry Pi 3 by using frameworks like Tensorflow Lite. 
\ESRm will propose simplifications of existing models to make them meet the real-time constraint on embedded devices and will test their accuracy on publicly available datasets as well as internal real customer data. 
The second objective of the project will be to investigate if and how hybrid platforms, like boards equipped with GPUs and FPGAs, can offer a different, more cost-effective solution to the problem of RTA of video streams in embedded platforms. 
A secondment in LIP6 in \sorbonneentity will train \ESRm with the background needed in heterogeneous computing architectures and the optimal resource allocation, which will then be applied to the domain of this project. 
During the 2-months secondment at \lundentity, \ESRm will use simulated datasets within the Open Data Project to deliver a starting point for deep learning techniques in HEP triggers, where the initial testing ground will be using energy deposits left in the detector by hadronic jets as images. This work will also have connections with \ESRa's project for identification of jets from heavy quarks.
}\tabularnewline\hline
\multicolumn{6}{|p{21.2cm}|}{\textbf{\Tstrut Expected Results:}
1. Development and testing of algorithms for resource-constrained platforms (conference paper). 
2. Investigation of hybrid platforms, together with LIP6 (peer-reviewed paper).
3. Proof-of-concept of computer vision algorithms on jet images (peer-reviewed paper)
\ESRm will receive a PhD in Computer Science and Engineering from \unibo.
}\tabularnewline\hline
\multicolumn{6}{|p{21.2cm}|}{\textbf{\Tstrut Secondments:}
\sorbonneentity, 3 months, Lacassagne. Heterogeneous computing for video streams in embedded platforms. 
\lundentity, 2 months, Doglioni. Sample toolkit for classification of hadronic jets. 
}\tabularnewline
\hline
\end{tabular}
}%
\end{center}